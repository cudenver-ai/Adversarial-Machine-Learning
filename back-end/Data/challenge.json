[
  {
    "img": "https://picsum.photos/800/450?image=442",
    "title": "Challenge Objective",
    "description": "The objective of this challenge is to create adversarial examples that can mislead a robust AI model. Participants must craft subtle perturbations that deceive the classifier while preserving image quality."
  },
  {
    "title": "Submission Guidelines",
    "description": "Submit the adversarial examples in the required format. Include a detailed README outlining the methods and algorithms used. Visual comparisons of the original and perturbed images are encouraged."
  },
  {
    "title": "Rules & Guidelines",
    "description": [
      "1) Submissions must adhere to the provided format.",
      "2) Perturbations should be subtle yet effective.",
      "3) Each team is allowed one submission per day.",
      "4) Follow ethical AI guidelines at all times."
    ]
  },
  {
    "img": "https://picsum.photos/800/450?image=692",
    "tag": "Dataset Description",
    "title": "Dataset Description",
    "description": "Participants will use the CIFAR-10 dataset and a pre-trained classifier. Use state-of-the-art adversarial techniques to craft perturbations that successfully deceive the model without compromising image integrity."
  }
]
