[
  {
    "block1": "%%capture\n!pip install git+https://github.com/RobustBench/robustbench.git # library for loading robust classifer\n!pip install -q foolbox # library for adversarial example generation",
    "block2": "from robustbench.utils import clean_accuracy\nfrom robustbench.utils import load_model\nimport matplotlib.pyplot as plt\nfrom torch import unique\nimport foolbox as fb\nimport numpy as np\nimport pickle\nimport torch\nimport os",
    "block3": "import gdown\noutput_file = 'cifar10.pt'\nfile_id = \"1A5gQCE0bHZhBlfcLQ2fFP5UygpgVkdAX\"\ngdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_file)",
    "block4": "cifar_data = torch.load('cifar10.pt')",
    "block5": "# Extract the images and labels tensors\nx_test = cifar_data['images']\ny_test = cifar_data['labels']\n\nprint(unique(y_test, return_counts=True))",
    "block6": "print(x_test.shape, y_test.shape)\nprint(torch.max(x_test), torch.min(x_test))",
    "block7": "model = load_model(model_name='Kireev2021Effectiveness_RLATAugMix', dataset='cifar10', threat_model='corruptions')",
    "block8": "# Check if GPU is available and set the device accordingly\nif torch.cuda.is_available():\n    device = torch.device('cuda')\n    print(\"Using GPU:\", torch.cuda.get_device_name(0))\nelse:\n    device = torch.device('cpu')\n    print(\"Using CPU\")\n\nmodel = model.to(device)\nx_test = x_test.to(device)\ny_test = y_test.to(device)",
    "block9": "model_fb = fb.PyTorchModel(model, bounds=(0, 1))",
    "block10": "_, advs, success = fb.attacks.LinfPGD(rel_stepsize=0.1, steps=20)(model_fb, x_test, y_test, epsilons=[8/255])",
    "block11": "print('Robust accuracy: {:.1%}'.format(1 - success.float().mean()))\nprint(clean_accuracy(model, x_test, y_test))",
    "block12": "import torch\nimport matplotlib.pyplot as plt\nimport random\n\n# Pass the perturbed images through the model to get the predicted labels\nwith torch.no_grad():  # No need to track gradients during inference\n    logits_adv = model(advs[0].to('cuda'))  # Get the logits for the adversarial examples\n\n# Get the predicted labels from the logits\npredicted_labels_adv = torch.argmax(logits_adv, dim=1)\n\n# Find which examples were misclassified (where predicted label != true label)\nmisclassified_indices = (predicted_labels_adv != y_test.to('cuda')).nonzero(as_tuple=True)[0]\n\n# Get the misclassified original and perturbed images, true labels, and incorrect labels\nmisclassified_images = advs[0][misclassified_indices]\nmisclassified_original_images = x_test.to('cuda')[misclassified_indices]\nmisclassified_predicted_labels = predicted_labels_adv[misclassified_indices]\nmisclassified_true_labels = y_test.to('cuda')[misclassified_indices]\n\n# Choose a random subset of misclassified images to display\nnum_images_to_show = min(10, len(misclassified_images))  # Limit to 10 images for display\nrandom_indices = random.sample(range(len(misclassified_images)), num_images_to_show)\n\n# Class names (assuming CIFAR-10)\nclass_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n               'dog', 'frog', 'horse', 'ship', 'truck']\n\n# Plot the original and misclassified perturbed images side by side\nplt.figure(figsize=(25, 5))\nfor i, idx in enumerate(random_indices):\n    # Original image\n    original_image = misclassified_original_images[idx]\n    true_label = misclassified_true_labels[idx].item()\n\n    # Perturbed image\n    perturbed_image = misclassified_images[idx]\n    incorrect_label = misclassified_predicted_labels[idx].item()\n\n    # Convert images from tensor to numpy and transpose from (C, H, W) to (H, W, C)\n    original_img = original_image.permute(1, 2, 0).cpu().numpy()\n    perturbed_img = perturbed_image.permute(1, 2, 0).cpu().numpy()\n\n    # Plot original image\n    plt.subplot(2, num_images_to_show, i+1)\n    plt.imshow(original_img, interpolation='none')\n    plt.title(f\"Original: {class_names[true_label]}\")\n    plt.axis('off')\n\n    # Plot perturbed (misclassified) image\n    plt.subplot(2, num_images_to_show, num_images_to_show + i + 1)\n    plt.imshow(perturbed_img, interpolation='none')\n    plt.title(f\"Perturbed: {class_names[incorrect_label]}\")\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()\n",
    "block13": "# Create the 'challenge' directory if it doesn't exist\nos.makedirs('challenge', exist_ok=True)\n\n# Path to save the adversarial examples\nfile_path = os.path.join('challenge', 'advs.pkl')\n\n# Save the 'advs' object\nwith open(file_path, 'wb') as f:\n    pickle.dump(advs, f)",
    "block14": ""
  }
]
